{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:35:57.429561Z",
     "start_time": "2025-09-24T14:35:57.403667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the ARFF file\n",
    "data = arff.loadarff('.old.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "\n",
    "# Convert columns from bytes to integers if necessary\n",
    "df = df.astype(int)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df.drop('Result', axis=1)\n",
    "y = df['Result']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")"
   ],
   "id": "66b38c7515647d99",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1964, 30)\n",
      "Testing set shape: (492, 30)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:35:58.818926Z",
     "start_time": "2025-09-24T14:35:57.433207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a pipeline that first scales the data, then runs the SVM\n",
    "svm_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', svm.SVC(random_state=42))\n",
    "])\n",
    "\n",
    "# Create a dictionary of models to test\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "\t\"SVM\": svm.SVC(random_state=42),\n",
    "\t\"SVM with Scaler\": svm_pipeline,\n",
    "\t\"Knn\": KNeighborsClassifier(n_neighbors=3),\n",
    "\t\"Linear SVM\": LinearSVC(random_state=42)\n",
    "}\n",
    "\n",
    "# Loop through and evaluate each model using cross-validation\n",
    "model_score = {}\n",
    "for name, model in models.items():\n",
    "    # Use 5-fold cross-validation and the F1-score as the metric\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='f1')\n",
    "    model_score[name] = np.mean(scores)\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(f\"Scores: {scores}\")\n",
    "    print(f\"Mean F1-Score: {np.mean(scores):.4f}\")\n",
    "    print(f\"Std Deviation: {np.std(scores):.4f}\\n\")\n"
   ],
   "id": "6a21a1770aa27092",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Logistic Regression ---\n",
      "Scores: [0.94857143 0.9244186  0.93409742 0.93714286 0.94186047]\n",
      "Mean F1-Score: 0.9372\n",
      "Std Deviation: 0.0081\n",
      "\n",
      "--- Random Forest ---\n",
      "Scores: [0.96045198 0.96022727 0.96209913 0.95402299 0.97994269]\n",
      "Mean F1-Score: 0.9633\n",
      "Std Deviation: 0.0087\n",
      "\n",
      "--- Gradient Boosting ---\n",
      "Scores: [0.95238095 0.95184136 0.96231884 0.96       0.96590909]\n",
      "Mean F1-Score: 0.9585\n",
      "Std Deviation: 0.0055\n",
      "\n",
      "--- SVM ---\n",
      "Scores: [0.95480226 0.95428571 0.96253602 0.9512894  0.96275072]\n",
      "Mean F1-Score: 0.9571\n",
      "Std Deviation: 0.0047\n",
      "\n",
      "--- SVM with Scaler ---\n",
      "Scores: [0.94886364 0.94318182 0.95930233 0.95156695 0.96571429]\n",
      "Mean F1-Score: 0.9537\n",
      "Std Deviation: 0.0079\n",
      "\n",
      "--- Knn ---\n",
      "Scores: [0.92351275 0.92479109 0.9244186  0.91907514 0.94350282]\n",
      "Mean F1-Score: 0.9271\n",
      "Std Deviation: 0.0085\n",
      "\n",
      "--- Linear SVM ---\n",
      "Scores: [0.94252874 0.92528736 0.93982808 0.94017094 0.93604651]\n",
      "Mean F1-Score: 0.9368\n",
      "Std Deviation: 0.0061\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:35:58.879789Z",
     "start_time": "2025-09-24T14:35:58.876909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find the model with the best Mean F1-Score\n",
    "sorted_models = sorted(model_score.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nModels sorted by Mean F1-Score:\")\n",
    "for model, score in sorted_models:\n",
    "    print(f\"{model}: {score:.4f}\")\n",
    "\n",
    "best_model = max(model_score, key=model_score.get)\n",
    "print(f\"Best model: {best_model}\")\n",
    "print(f\"Best score: {model_score[best_model]:.4f}\")\n"
   ],
   "id": "ca7cbba0de5f35bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Models sorted by Mean F1-Score:\n",
      "Random Forest: 0.9633\n",
      "Gradient Boosting: 0.9585\n",
      "SVM: 0.9571\n",
      "SVM with Scaler: 0.9537\n",
      "Logistic Regression: 0.9372\n",
      "Linear SVM: 0.9368\n",
      "Knn: 0.9271\n",
      "Best model: Random Forest\n",
      "Best score: 0.9633\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:36:26.839246Z",
     "start_time": "2025-09-24T14:35:58.893850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluating the Results of GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'max_depth': [10, 20, 30, None],   # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10]   # Minimum number of samples to split a node\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    ")\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation F1-score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# About 18 Sec"
   ],
   "id": "eb6e4da17da35df9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best cross-validation F1-score: 0.9641\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:38:28.276763Z",
     "start_time": "2025-09-24T14:36:26.894388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluating the Results of RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint # Good for defining a range of integers\n",
    "\n",
    "# Define the parameter distribution for Random Forest\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),         # Number of trees\n",
    "    'max_depth': [10, 20, 30, 40, 50, None],    # Max depth of the tree\n",
    "    'min_samples_split': randint(2, 11)        # Min samples to split a node\n",
    "}\n",
    "\n",
    "# Create a RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=100,  # Try 100 different combinations\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the random search to the data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(f\"Best parameters found: {random_search.best_params_}\")\n",
    "print(f\"Best cross-validation F1-score: {random_search.best_score_:.4f}\")\n",
    "\n",
    "# About 5 Mins"
   ],
   "id": "357fe287e8bedf7c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'max_depth': 30, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best cross-validation F1-score: 0.9640\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:38:28.371441Z",
     "start_time": "2025-09-24T14:38:28.356641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model Validation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Get the best estimator from the grid search\n",
    "best_rf_model = random_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "# Print a detailed classification report\n",
    "print(\"\\n--- Final Model Evaluation on Test Set ---\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Legitimate (-1)', 'Phishing (1)']))\n",
    "\n",
    "# Display the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ],
   "id": "ef4137e081996354",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Model Evaluation on Test Set ---\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Legitimate (-1)       0.97      0.97      0.97       273\n",
      "   Phishing (1)       0.96      0.96      0.96       219\n",
      "\n",
      "       accuracy                           0.97       492\n",
      "      macro avg       0.96      0.97      0.97       492\n",
      "   weighted avg       0.97      0.97      0.97       492\n",
      "\n",
      "Confusion Matrix:\n",
      "[[264   9]\n",
      " [  8 211]]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Building a Complete ML Pipeline for Random Forest Model\n",
    "\n",
    "Based on your existing code, I'll create a comprehensive pipeline that includes preprocessing, hyperparameter tuning, and model evaluation."
   ],
   "id": "7d0063d1105e869e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:38:28.378947Z",
     "start_time": "2025-09-24T14:38:28.375233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "import joblib\n",
    "\n",
    "# Create a comprehensive pipeline with preprocessing and model\n",
    "rf_pipeline = Pipeline([\n",
    "\t('preprocessor', StandardScaler()),\n",
    "\t('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "print(\"Random Forest Pipeline created successfully\")\n",
    "print(f\"Pipeline steps: {rf_pipeline.steps}\")"
   ],
   "id": "31253eae1197a53",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Pipeline created successfully\n",
      "Pipeline steps: [('preprocessor', StandardScaler()), ('classifier', RandomForestClassifier(random_state=42))]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:38:28.395390Z",
     "start_time": "2025-09-24T14:38:28.392168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define hyperparameter grid for pipeline\n",
    "pipeline_param_grid = {\n",
    "\t'classifier__n_estimators': [100, 200, 300],\n",
    "\t'classifier__max_depth': [10, 20, 30, None],\n",
    "\t'classifier__min_samples_split': [2, 5, 10],\n",
    "\t'classifier__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV with the pipeline\n",
    "pipeline_grid_search = GridSearchCV(\n",
    "\testimator=rf_pipeline,\n",
    "\tparam_grid=pipeline_param_grid,\n",
    "\tcv=5,\n",
    "\tscoring='f1',\n",
    "\tverbose=1\n",
    ")\n",
    "\n",
    "print(\"Pipeline GridSearchCV object created\")\n",
    "print(\n",
    "\tf\"Total combinations to test: {len(pipeline_param_grid['classifier__n_estimators']) * len(pipeline_param_grid['classifier__max_depth']) * len(pipeline_param_grid['classifier__min_samples_split']) * len(pipeline_param_grid['classifier__min_samples_leaf'])}\")"
   ],
   "id": "b6e9b65ab140a795",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline GridSearchCV object created\n",
      "Total combinations to test: 108\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:39:52.603593Z",
     "start_time": "2025-09-24T14:38:28.408714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fit the pipeline with hyperparameter tuning\n",
    "print(\"Training pipeline with hyperparameter tuning...\")\n",
    "pipeline_grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best pipeline parameters: {pipeline_grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation F1-score: {pipeline_grid_search.best_score_:.4f}\")"
   ],
   "id": "23bed7855ef449bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training pipeline with hyperparameter tuning...\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best pipeline parameters: {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 100}\n",
      "Best cross-validation F1-score: 0.9641\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:39:52.725620Z",
     "start_time": "2025-09-24T14:39:52.712160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the best pipeline\n",
    "best_pipeline = pipeline_grid_search.best_estimator_\n",
    "\n",
    "# Make predictions using the complete pipeline\n",
    "pipeline_predictions = best_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate pipeline performance\n",
    "print(\"=== Pipeline Performance on Test Set ===\")\n",
    "print(classification_report(y_test, pipeline_predictions, target_names=['Legitimate (-1)', 'Phishing (1)']))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, pipeline_predictions))\n",
    "\n",
    "# Calculate F1 score\n",
    "pipeline_f1_score = f1_score(y_test, pipeline_predictions)\n",
    "print(f\"\\nPipeline F1-Score: {pipeline_f1_score:.4f}\")"
   ],
   "id": "fcd0f9faee99c575",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Pipeline Performance on Test Set ===\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Legitimate (-1)       0.97      0.96      0.97       273\n",
      "   Phishing (1)       0.95      0.96      0.96       219\n",
      "\n",
      "       accuracy                           0.96       492\n",
      "      macro avg       0.96      0.96      0.96       492\n",
      "   weighted avg       0.96      0.96      0.96       492\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[263  10]\n",
      " [  9 210]]\n",
      "\n",
      "Pipeline F1-Score: 0.9567\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:39:52.761379Z",
     "start_time": "2025-09-24T14:39:52.735221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the trained pipeline\n",
    "joblib.dump(best_pipeline, 'best_rf_pipeline.pkl')\n",
    "\n",
    "\n",
    "# Create a prediction function using the pipeline\n",
    "def predict_phishing(features):\n",
    "\t\"\"\"\n",
    "    Predict if a URL is phishing using the trained pipeline\n",
    "    \n",
    "    Parameters:\n",
    "    features: array-like, shape (n_features,) or (n_samples, n_features)\n",
    "    \n",
    "    Returns:\n",
    "    predictions: array, predicted labels (-1 for legitimate, 1 for phishing)\n",
    "    \"\"\"\n",
    "\treturn best_pipeline.predict(features)\n",
    "\n",
    "\n",
    "# Create a prediction probability function\n",
    "def predict_phishing_proba(features):\n",
    "\t\"\"\"\n",
    "    Get prediction probabilities using the trained pipeline\n",
    "    \n",
    "    Parameters:\n",
    "    features: array-like, shape (n_features,) or (n_samples, n_features)\n",
    "    \n",
    "    Returns:\n",
    "    probabilities: array, shape (n_samples, 2) - probabilities for each class\n",
    "    \"\"\"\n",
    "\treturn best_pipeline.predict_proba(features)\n",
    "\n",
    "\n",
    "print(\"Pipeline saved as 'best_rf_pipeline.pkl'\")\n",
    "print(\"Prediction functions created successfully\")"
   ],
   "id": "b42c98cd43d60dcc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline saved as 'best_rf_pipeline.pkl'\n",
      "Prediction functions created successfully\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:39:52.776875Z",
     "start_time": "2025-09-24T14:39:52.766176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compare pipeline performance with previous best model\n",
    "print(\"=== Model Comparison ===\")\n",
    "print(f\"Previous best Random Forest F1-score: {f1_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Pipeline Random Forest F1-score: {pipeline_f1_score:.4f}\")\n",
    "\n",
    "improvement = pipeline_f1_score - f1_score(y_test, y_pred)\n",
    "print(f\"Performance improvement: {improvement:.4f}\")\n",
    "\n",
    "# Display feature importance from the pipeline\n",
    "feature_importance = best_pipeline.named_steps['classifier'].feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Create a dataframe for better visualization\n",
    "importance_df = pd.DataFrame({\n",
    "\t'feature': feature_names,\n",
    "\t'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n=== Top 10 Most Important Features ===\")\n",
    "print(importance_df.head(10))"
   ],
   "id": "809cbc8adc48dd99",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Comparison ===\n",
      "Previous best Random Forest F1-score: 0.9613\n",
      "Pipeline Random Forest F1-score: 0.9567\n",
      "Performance improvement: -0.0046\n",
      "\n",
      "=== Top 10 Most Important Features ===\n",
      "                        feature  importance\n",
      "7                SSLfinal_State    0.290133\n",
      "13                URL_of_Anchor    0.228364\n",
      "25                  web_traffic    0.115515\n",
      "5                 Prefix_Suffix    0.112203\n",
      "6             having_Sub_Domain    0.044516\n",
      "23                age_of_domain    0.038779\n",
      "26                    Page_Rank    0.032070\n",
      "8   Domain_registeration_length    0.023079\n",
      "14                Links_in_tags    0.021288\n",
      "12                  Request_URL    0.015403\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:39:52.791346Z",
     "start_time": "2025-09-24T14:39:52.786454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a complete ML pipeline class for reusability\n",
    "class PhishingDetectionPipeline:\n",
    "\tdef __init__(self):\n",
    "\t\tself.pipeline = None\n",
    "\t\tself.is_trained = False\n",
    "\n",
    "\tdef build_pipeline(self):\n",
    "\t\t\"\"\"Build the ML pipeline\"\"\"\n",
    "\t\tself.pipeline = Pipeline([\n",
    "\t\t\t('preprocessor', StandardScaler()),\n",
    "\t\t\t('classifier', RandomForestClassifier(random_state=42))\n",
    "\t\t])\n",
    "\t\treturn self.pipeline\n",
    "\n",
    "\tdef train(self, X_train, y_train, hyperparameter_tuning=True):\n",
    "\t\t\"\"\"Train the pipeline\"\"\"\n",
    "\t\tif self.pipeline is None:\n",
    "\t\t\tself.build_pipeline()\n",
    "\n",
    "\t\tif hyperparameter_tuning:\n",
    "\t\t\tparam_grid = {\n",
    "\t\t\t\t'classifier__n_estimators': [100, 200, 300],\n",
    "\t\t\t\t'classifier__max_depth': [10, 20, 30, None],\n",
    "\t\t\t\t'classifier__min_samples_split': [2, 5, 10]\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\tgrid_search = GridSearchCV(\n",
    "\t\t\t\tself.pipeline, param_grid, cv=5, scoring='f1', n_jobs=-1\n",
    "\t\t\t)\n",
    "\t\t\tgrid_search.fit(X_train, y_train)\n",
    "\t\t\tself.pipeline = grid_search.best_estimator_\n",
    "\t\t\tself.best_params = grid_search.best_params_\n",
    "\t\t\tself.best_score = grid_search.best_score_\n",
    "\t\telse:\n",
    "\t\t\tself.pipeline.fit(X_train, y_train)\n",
    "\n",
    "\t\tself.is_trained = True\n",
    "\n",
    "\tdef predict(self, X):\n",
    "\t\t\"\"\"Make predictions\"\"\"\n",
    "\t\tif not self.is_trained:\n",
    "\t\t\traise ValueError(\"Pipeline must be trained before making predictions\")\n",
    "\t\treturn self.pipeline.predict(X)\n",
    "\n",
    "\tdef predict_proba(self, X):\n",
    "\t\t\"\"\"Get prediction probabilities\"\"\"\n",
    "\t\tif not self.is_trained:\n",
    "\t\t\traise ValueError(\"Pipeline must be trained before making predictions\")\n",
    "\t\treturn self.pipeline.predict_proba(X)\n",
    "\n",
    "\tdef save_model(self, filename):\n",
    "\t\t\"\"\"Save the trained pipeline\"\"\"\n",
    "\t\tif not self.is_trained:\n",
    "\t\t\traise ValueError(\"Pipeline must be trained before saving\")\n",
    "\t\tjoblib.dump(self.pipeline, filename)\n",
    "\n",
    "\tdef load_model(self, filename):\n",
    "\t\t\"\"\"Load a trained pipeline\"\"\"\n",
    "\t\tself.pipeline = joblib.load(filename)\n",
    "\t\tself.is_trained = True\n",
    "\n",
    "\n",
    "# Example usage of the pipeline class\n",
    "phishing_pipeline = PhishingDetectionPipeline()\n",
    "print(\"PhishingDetectionPipeline class created successfully\")\n"
   ],
   "id": "914741801a381d3f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhishingDetectionPipeline class created successfully\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
